ğŸ§¬ 3D In-Vitro Lead Intelligence Agent

An AI-assisted decision intelligence pipeline that identifies, enriches, and prioritizes adoption-ready stakeholders for 3D in-vitro models used in toxicology and drug discovery.
The system combines scientific signals, business context, and ML-assisted ranking to help teams decide who to engage, why they matter, and why now.

ğŸ“Š Live Demo

Interactive Streamlit dashboard demonstrating persona-driven lead identification and prioritization:

ğŸ‘‰ http://localhost:8501/

ğŸ›ï¸ High-Level Architecture

The application follows an agent-style pipeline, orchestrated within the Streamlit app:

User Inputs (Persona + Scientific Context)
        â†“
Identification Layer
  â€¢ LinkedIn-like professional discovery (Mock API)
  â€¢ Scientific signal discovery (Real PubMed API)
        â†“
Enrichment Layer
  â€¢ Funding stage & budget readiness (Mock API)
  â€¢ Location & hub intelligence
        â†“
Decision Intelligence Engine
  â€¢ Feature engineering
  â€¢ ML-assisted propensity scoring (Random Forest)
  â€¢ Business rule interpretation
        â†“
Ranked Dashboard Output
  â€¢ Fit classification
  â€¢ Recommended outreach action


The pipeline executes each time the user runs the Data Pipeline from the UI.

ğŸ”„ Pipeline Stages
Stage 1: Identification

The agent identifies relevant professionals based on:

Role persona (e.g., Director of Toxicology, Head of Preclinical Safety)

Scientific context (e.g., DILI, hepatic models, organ-on-chip)

Sources:

Mocked professional network API (LinkedIn / Xing equivalent)

Real PubMed (NCBI E-utilities) API for recent publications

Stage 2: Enrichment

Each identified profile is enriched with:

Company funding stage (Series A/B, Seed, Public, etc.)

Budget readiness inference

Geographic context (HQ vs remote, major biotech hubs)

This layer converts raw profiles into commercially interpretable entities.

Stage 3: Decision Intelligence & Ranking

The enriched leads are passed through a decision intelligence engine that:

Performs feature engineering (seniority, funding, hub presence)

Uses a Random Forest classifier to estimate adoption propensity

Translates scores into human-readable insights

Outputs include:

Propensity to Collaborate (%)

Scientific + Business Fit (High / Medium / Low)

Recommended Action

High Priority Outreach

Warm Lead

Monitor

This ensures the output is actionable, not just ranked.

ğŸ§  Key Design Decisions & Problems Addressed
1ï¸âƒ£ Explainability over Black-Box ML

Problem: Pure ML scoring is difficult for BD teams to trust.
Solution: ML is used to assist ranking, while business rules clearly interpret outcomes into fit levels and actions.

2ï¸âƒ£ Compliance-Aware Data Strategy

Problem: Scraping platforms like LinkedIn violates ToS and is unreliable.
Solution: Proprietary sources are abstracted via mocked APIs, while PubMed is accessed through its official public API, preserving a production-ready architecture without compliance risk.

3ï¸âƒ£ Timing-Aware Lead Prioritization

Problem: Relevance alone does not indicate urgency or readiness.
Solution: The system explicitly surfaces:

Recent scientific activity

Funding recency

Decision-making seniority

This aligns ranking with budget timing and adoption readiness.

4ï¸âƒ£ Persona-Driven Decision Context

Problem: Different stakeholders prioritize different signals.
Solution: The agent accepts persona and scientific context as first-class inputs, enabling scenario-specific prioritization.

ğŸ“ˆ Output & Usability

The final dashboard provides:

Ranked, searchable lead list

Clear prioritization logic

Export-ready structure for downstream workflows

The system is designed to support real BD decision-making, not just data exploration.

ğŸ› ï¸ Tech Stack

Python

Streamlit â€“ interactive UI & orchestration

scikit-learn â€“ Random Forest classifier

Pandas / NumPy â€“ data processing

Requests + XML parsing â€“ PubMed API integration

ğŸ“‚ Repository Structure
.
â”œâ”€â”€ app.py              # Streamlit app & pipeline orchestration
â”œâ”€â”€ data_sources.py     # Mock APIs + PubMed integration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ”§ Local Setup

Clone the repository and create a virtual environment:

git clone <repo-url>
cd 3d-invitro-lead-intelligence
python -m venv .venu
source .venu/bin/activate  # Windows: .venu\Scripts\activate
pip install -r requirements.txt
streamlit run app.py


No API keys are required.

ğŸ“¡ Compliance & Ethics

No LinkedIn scraping

No ToS-violating data collection

PubMed accessed via official public API

Proprietary data abstracted responsibly

ğŸ”® Future Extensions

Persistent storage for historical runs

Explainable per-lead score breakdown

Integration with licensed data providers

Multi-persona weighting strategies

âœ… Summary

This project demonstrates how AI-assisted decision intelligence can be applied to the 3D in-vitro and predictive toxicology domain, combining scientific relevance, business readiness, and explainable prioritization into a practical, production-minded tool.
